#!/usr/bin/python3

from neural_network import NN,  get_activation_funcs_by_name
from data_process import load, preprocess_data, conf_parser, generate_data_rand
import sys


def print_help():
    print("-----------------------------------------------------------------------------------------------------------------")
    print("Multilayer perceptron")
    print("Usage:")
    print("   python  mlp.py  <--options> <config.json> <data.csv> [params.json]")
    print("Options:")
    print("  -s:  Split dataset into (train.csv) and (test.csv), no params required")
    print("  -t:  Train dataset, if params.json is provided, it performs fine tuning.")
    print("  -p:  Test on a test dataset, if params.json is provided, it performs prediction based on trained model.")
    print("  -help:  Show help messages.")
    print("  -More features to come.")
    print("Note:")
    print("  There is built in dataset generated by script, use --gen-data1d to replace dataset")
    print("-----------------------------------------------------------------------------------------------------------------")


def mlp_train(nn, conf, inputs, truths):
    nn.train(inputs, truths, 
             conf["max_epoch"], 
             conf["learning_rate"], 
             batch_size=conf["batch_size"], 
             test_ratio=conf["train_ratio"],
             threshold=conf["threshold"],
             animation=conf["animation"])
    nn.save_plots()


def mlp_getdata(source, conf):
    if source == "--gen-data1d":
        inputs, truths = generate_data_rand(142, 500, 0.02)
    else:
        df = load(source, False)
        if df is None:
            sys.exit(1)
        inputs, truths = preprocess_data(df)
    return inputs, truths


def mlp_splitdata(config_file, file, seed, ratio=0.8):
    print(config_file)
    conf = conf_parser(config_file)
    df = load(file, conf["index"])
    if df is None:
        sys.exit(1)

    df_shuffled = df.sample(frac=1, random_state=seed).reset_index(drop=True)
    l = len(df_shuffled)
    train_data = df_shuffled[:int(ratio * l)]
    test_data = df_shuffled[int(ratio * l):]
    print("[Original Data]", df.shape)
    print("[Train data]", train_data.shape)
    print("[Test data]", test_data.shape)
    train_data.to_csv("data/train.csv", index=False, encoding="utf-8")
    test_data.to_csv("data/test.csv", index=False, encoding="utf-8")
    print("[Save splited data into (data/train.csv) (data/test.csv)]")


def mlp_create_nn(argv):
    conf = conf_parser(argv[2])
    if conf is None:
        sys.exit(1)
    nn = NN(conf["shape"], get_activation_funcs_by_name(conf["activation_funcs"]), 
            conf["weights_init"],
            classification=conf["classification"],
            loss=conf["loss"])
    inputs, truths = mlp_getdata(argv[3], conf)
    if len(argv) == 5:
        nn.load_weights(argv[4])
    return nn, inputs, truths, conf


def main():
    try:
        argv = sys.argv
        if len(argv) == 1 or ((len(argv) == 2 and argv[1] == "--help")):
            print_help()
        elif argv[1] == "-s" and len(argv) == 4:
            mlp_splitdata(argv[2], argv[3], 132, 0.8)
        elif len(argv) == 4 or len(argv) == 5:
            nn, inputs, truths, conf = mlp_create_nn(argv)
            if argv[1] == "-t":
                mlp_train(nn, conf, inputs, truths)
            elif argv[1] == "-p":
                nn.test(inputs, truths)
            else:
                raise ValueError("Wrong arguments. Try: python mlp.py --help")
        else:
            raise ValueError("Wrong arguments. Try: python mlp.py --help")

    except KeyboardInterrupt as e:
        print()
        print("Stopped by user.\033[?25h")

    except Exception as e:
        print("Error:", e)


if __name__ == "__main__":
    main()